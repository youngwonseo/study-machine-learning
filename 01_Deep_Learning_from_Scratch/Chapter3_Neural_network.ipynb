{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter3. 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 신경망\n",
    "#### 3.1.1 신경망이란? (퍼셉트론과 비교관점에서)\n",
    "* 여러개의 퍼셉트론(뉴런)들이 모여 여러층(레이어)을 이룬다.\n",
    "* 층의 위치에 따라 입력층, 은닉층, 출력층이라 한다. \n",
    "* 다음은 신경망 아키텍처를 표현한 그림이다. (http://cs231n.github.io/neural-networks-1/)\n",
    "![](http://cs231n.github.io/assets/nn1/neural_net.jpeg)\n",
    "* 역전파 알고리즘을 이용하여 가중치(weight)를 학습할 수 있다.\n",
    "\n",
    "#### 3.1.2 동작방식\n",
    "* 퍼셉트론은 다음과 같이 동작한다.\n",
    "![](http://neuralnetworksanddeeplearning.com/images/tikz0.png)\n",
    "![](https://latex.codecogs.com/gif.latex?y%3D%5Cbegin%7Bcases%7D%200%5Cquad%20%28b&plus;%7B%20w%20%7D_%7B%201%20%7D%7B%20x%20%7D_%7B%201%20%7D&plus;%7B%20w%20%7D_%7B%202%20%7D%7B%20x%20%7D_%7B%202%20%7D&plus;%7B%20w%20%7D_%7B%203%20%7D%7B%20x%20%7D_%7B%203%20%7D%5Cle%200%20%5C%5C%201%5Cquad%20%28b&plus;%7B%20w%20%7D_%7B%201%20%7D%7B%20x%20%7D_%7B%201%20%7D&plus;%7B%20w%20%7D_%7B%202%20%7D%7B%20x%20%7D_%7B%202%20%7D&plus;%7B%20w%20%7D_%7B%203%20%7D%7B%20x%20%7D_%7B%203%20%7D%3E0%20%5Cend%7Bcases%7D)\n",
    "* 위를 간략하게 설명하자면 입력 데이터(x)와 가중치(w)를 곱한 후 기저(b)를 더한 결과과 0보다 크면 1 아니면 0을 출력한다. 가장 기본적인 퍼셉트론의 동작방식이다.\n",
    "* 그렇다면 신경망은 뉴런은 어떻게 동작할까? 다음은 그 예시이다.\n",
    "> \\\\( y=h(b+{ w }_{ 1 }{ x }_{ 1 }+{ w }_{ 2 }{ x }_{ 2 }+{ w }_{ 3 }{ x }_{ 3 }) \\\\)\n",
    "* 퍼셉트론과 차이점은 활성화함수(h)가 적용된다. 즉 활성화 함수의 속성에 따라 출력(활성화 여부, 활성화 정도)이 결정된다. \n",
    "* 활성화 함수는 역전파 알고리즘(가중치 학습)을 사용할 때 중요하게 작용한다. \n",
    "* 즉, 역전파 알고리즘 적용가능여부에 따라 퍼셉트론과 신경망의 차이를 알 수 있고, 이 부분에서 활성화 함수의 역활은 매우 크다는것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 활성화 함수\n",
    "* 여기서는 대표적인 몇 가지의 활성화 함수를 알아보자.\n",
    "\n",
    "#### 3.2.1 계단\n",
    "* 가장 간단한 활성화 함수로 입력에 따라 0 아니면 1을 출력한다.\n",
    "![](https://latex.codecogs.com/gif.latex?h%28x%29%3D%5Cbegin%7Bcases%7D%201%5Cquad%20%28x%3E0%29%20%5C%5C%200%5Cquad%20%28x%5Cle%200%29%20%5Cend%7Bcases%7D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 시그모이드\n",
    "* 0과 1사이를 출력하며 다음과 같은 수식과 다음과 같은 출력을 가진다.\n",
    "\n",
    "![](http://cs231n.github.io/assets/nn1/sigmoid.jpeg)\n",
    "![](https://latex.codecogs.com/gif.latex?h%28x%29%3D%5Cfrac%20%7B%201%20%7D%7B%201&plus;exp%28-x%29%20%7D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 하이퍼블릭 \n",
    "* 시스모이드와 같이 0과 1사이를 출력한다.\n",
    "> \n",
    "![](http://cs231n.github.io/assets/nn1/tanh.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 ReLU\n",
    "* gradient vanishing 문제를 해결하여 역전파에 최적화된 결과를 출력한다.\n",
    "* 이는 역전파 시 미분을 통해 오차를 찾아가는 과정에서 vanishing으로 학습할 값을 잃어버리는 것을 막는다.\n",
    "* 참조논문 : http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.6419&rep=rep1&type=pdf\n",
    "* 다음과 같은 수식과 출력을 갖는다.\n",
    "![](https://latex.codecogs.com/gif.latex?h%28x%29%3D%5Cbegin%7Bcases%7D%20x%5Cquad%20%28x%3E0%29%20%5C%5C%200%5Cquad%20%28x%5Cle%200%29%20%5Cend%7Bcases%7D)\n",
    "![](http://cs231n.github.io/assets/nn1/relu.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5  비선형함수\n",
    "* 위에서 몇 가지 활성화함수가 나열되었다. 자세히 살펴보면 모두 비선형 함수라는 것을 알 수 있다.\n",
    "* 신경망에서는 이와 같이 비선형함수를 활성화 함수로 사용해야한다. 선형함수를 사용할 시 은닉층을 여러개하는 의미가 없어지기 때문이다.\n",
    "* 예를 들어 선형함수 h(x) = cx가 존재할 경우 3개의 층을 이용하여 y(x) = h(h(h(x))) 와 같이 층을 이루었을때 결과는 y(x) = cccx와 같이 선형함수 이다. 이는 은닉층이 없이 표현가능하다. y(x)=(c^3)x\n",
    "* 은닉층을 여러개하는 해택을 얻고 싶다면 활성화 함수는 반드시 비선형 함수로 선택하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 출력층\n",
    "\n",
    "#### 3.3.1 항등함수\n",
    "#### 3.3.2 소프트맥스\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 구현\n",
    "#### 3.4.1 기본적인 구현\n",
    "* 일단 모델을 가장 직관적으로 구현해보자.\n",
    "* 2개의 입력과 하나의 은닉층에 3개의 뉴련, 2개의 출력을 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5],[0.2, 0.4, 0.6]])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([[0.1, 0.4],[0.2, 0.5],[0.3, 0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1, 0.3],[0.2, 0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "    \n",
    "    return network\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x,W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1,W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "network = init_network()\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)\n",
    "print(np.sum(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
